# evaluacion-mle-wm

**Contexto:**

Un Científico de Datos ha desarrollado el modelo de ML que se encuentra en el archivo "modelo_DS.ipynb" el cual predice si lloverá o no al dia siguiente. Puedes encontrar la documentación acerca de los datos, así como los datos aquí: https://www.kaggle.com/jsphyg/weather-dataset-rattle-package

Sin embargo, durante el proceso de desarrollo de este codigo se fueron acumulando elementos con una estructura deficiente que ponen en riesgo la aplicabilidad, escalamiento y el monitoreo constante del performance del modelo

**Instrucciones**

Deberás refactorizar todo el código del archivo "modelo_DS.ipynb" de tal manera que sea un código estructurado, optimizado y listo para ser ejecutado en un proceso productivo. 

Tu refactorización deberá cumplir al menos lo siguiente:

* Estructuración de carpetas (justifica por que elegiste esta estructura).
* Buenas prácticas de codificación con Python
* Un archivo "main" donde se orquestará todo el proceso  (Puedes incluir varios scripts para todo el proceso pero uno de ellos tiene que ser el main)
* Documento que redacte la nueva estructura y conclusiones respecto a las deficiencias encontradas en el codigo y como se resolvieron.
* Redacta una respuesta a la pregunta: Como interactúa la estructura de carpetas propuesta con el ambiente productivo? Aquí puede ser de manera escrita o mediante un diagrama de flujo.

Recuerda que tu respuesta puede ser un correo que contenga la carpeta comprimida (.zip) con tus resultados a mi correo con copia a mi correo personal (ambos están copiados en este mismo mail) por temas de fitlro de seguridad de la compañia para archivos comprimidos.

## Insights (Response to )

1. Filtering features using a correlation matrix is a common technique in feature selection, particularly in algorithms that can suffer from multicollinearity (like linear regression or logistic regression). However, when it comes to Decision Tree algorithms, the situation is a bit different.

2. I considered that isn't necessary to split the database by location, because   training models could be increase the complex to deploy them, however the  location feature coulbe take as a covariance and it implement  a get_dummies for handle it

3. I stablish a threshold 0.3 to handle droped Nan registers